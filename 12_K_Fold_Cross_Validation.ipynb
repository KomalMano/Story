{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.K Fold Cross Validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFjd7kUDC5zQEbIENWo21X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KomalMano/Story/blob/master/12_K_Fold_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kibU3xq3hSke"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIRsI-qHSSam"
      },
      "source": [
        "digits = load_digits()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMNMcBMuSS50"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyu0p0nNSaOE"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(digits.data, digits.target,test_size=0.3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t-Cf1FsStbO",
        "outputId": "cab2a6b1-95b6-47f0-f83c-f0156fb091f8"
      },
      "source": [
        "#now use different classifier\n",
        "#the 1st classifier i m use to LogisticRegression \n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "lr.score(X_test,y_test)\n",
        "#Classifier is basically ML model which tries to classify ur samples\n",
        "#and i train it using xtrain ytrain "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od6c77H_TzER",
        "outputId": "0415e39e-16b5-4779-a915-507c603dd8ec"
      },
      "source": [
        "#I have many other model like SVM\n",
        "#Now i want to try SVM. How SVM performs\n",
        "svm = SVC()\n",
        "svm.fit(X_train,y_train)\n",
        "svm.score(X_test,y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987037037037037"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDtuCFRUUVlM",
        "outputId": "26c2529a-66f5-4783-a912-1b517c67ba8f"
      },
      "source": [
        "#Now try random forest as well\n",
        "rf = RandomForestClassifier(n_estimators=140)\n",
        "rf.fit(X_train,y_train)\n",
        "rf.score(X_test,y_test)\n",
        "#this was a quick way of measuring the performance of these 3 models\n",
        "\n",
        "#now thisworks in practicle situation but what happen is the distribution of samples in the X_train and X_test is not uniform right .\n",
        "#when i run this method 1 more time . Now my samples will change totally "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9703703703703703"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvjiwaj8UWAb"
      },
      "source": [
        "\n",
        "#train_test_split method have 1 problem . U can not run it only 1 time and say the particular model is better the other model . So u have to run this train_test_split multiple time.\n",
        "#so every time it's changing.\n",
        "\n",
        "#Now let's try K FOLD\n",
        "#So 1st use K FOLD API demonstrate what exactly doing.\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbnPdbkKUU29",
        "outputId": "b705f38a-9706-424b-c1ec-adda8754662e"
      },
      "source": [
        "kf = KFold(n_splits=3) #here we want to specify how many folds we will like\n",
        "kf # here is created that"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=3, random_state=None, shuffle=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPxQnBRlYDv8",
        "outputId": "a8b7d66a-6ec2-4a20-9c37-444a8af7c9f1"
      },
      "source": [
        "#and the way u use this KFold on the Datasets\n",
        "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]): #now my kFold is ready\n",
        "  print(train_index, test_index)\n",
        "  #So whrn i run this , what exactly happeing in this .kf.split() gives iterator and iterator return train and test for each of the iterations .\n",
        "  #So split divided into 3 folds , 3 each. 1st iteration use 1 fold for testing which is this [0,1,2] and remaining 2 folds for training which is this [3 4 5 6 7 8].\n",
        "  #In the 2nd iteration mode is to training 0 1 2 and this fold is to testing 3 4 5.\n",
        "  #it repeate the procedure like that "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 5 6 7 8] [0 1 2]\n",
            "[0 1 2 6 7 8] [3 4 5]\n",
            "[0 1 2 3 4 5] [6 7 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuPAlDtgYEEZ"
      },
      "source": [
        "#Now we are going to use kFolds for our digits example .So to simplify the things .\n",
        "#I m going to write this generic method call get_score which take model as an input. \n",
        "def get_score(model, X_train, X_test, y_train, y_test):\n",
        "  model.fit(X_train,y_train) # fit mean to train our model\n",
        "  return model.score(X_test, y_test) # once the training is done it will return the model score using the test sample u have supplying as an argument to this method . Now this method is prety poweful. We could have use this method to measure performance of these guys as well.\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQyvRrEDYEX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd78585-95de-48f2-9799-108fa3bb0f01"
      },
      "source": [
        "#Lets just quickly show u . Lets instead of repeting these 3 lines as like previous regression model svm model.\n",
        "#I just call the get_score method here \n",
        "get_score(LogisticRegression(),X_train,X_test,y_train,y_test)\n",
        "#It should give me the score."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9_r-nSRLuh-",
        "outputId": "5721fb21-097b-4f81-8cd7-85b660e4edcc"
      },
      "source": [
        "#Same could i have done for SVC here \n",
        "get_score(SVC(),X_train,X_test,y_train,y_test)\n",
        "#it's just modulizing our code."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987037037037037"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUjOKqvOLu_m"
      },
      "source": [
        "#So once we have this method ready.I m going to now use kFolds on our digits datasets .\n",
        "from sklearn.model_selection import StratifiedKFold # StratifiedKFold is similarl to kFold .But StratifiedKFold is little bit better than that when u seperating out over folds it will divide the each of the classification categories in a uniform way and this could be very helpful.\n",
        "#bcz imagine u r creating 3 folds for eg our iris dataset and 2 folds have a 2 types of flower . ! fold just an very different types of flowers then it might create a problems. That's way use StratifiedKFold is better.\n",
        "\n",
        "#people usually use 10 splits but just to keep things simple . I m using 3 here .\n",
        "folds = StratifiedKFold(n_splits=3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wKSaFoYEoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df40c47-21de-453d-f8bb-38304269f7fb"
      },
      "source": [
        "#Onc u have ur folds ready . \n",
        "#So this method StratifiedKFold(n_splits=3) is exactly same as this KFold(n_splits=3)\n",
        "#So we are doing repeating same kind of thing . But we are working on the real life eg of digits datasets .\n",
        "scores_lr = [] # i wll prepare the scores array to prepare our scores of different model\n",
        "scores_svm = []\n",
        "scores_rf = []\n",
        "\n",
        "# here we are doing the same exact thing in the previosly .\n",
        " # But here we use real data instead of dummy data \n",
        "for train_index,test_index in kf.split(digits.data):\n",
        "  X_train,X_test,y_train,y_test = digits.data[train_index],digits.data[test_index], \\\n",
        "                                  digits.target[train_index],digits.target[test_index]\n",
        "  #now its time to measure the performance of 3 of our model in each iteration \n",
        "  #So we have 3 folds, this for loop will gone a repeate 3 times . it will take every time xrain ytrain ytrain ytest.\n",
        "  #and will measure performance of our model and then will append the scores of the empty arrays .\n",
        "  #scores_lr = []\n",
        "  #scores_svm = []\n",
        "  #scores_rf = []\n",
        "  #So that r we doing .\n",
        "  scores_lr.append(get_score(LogisticRegression(),X_train,X_test,y_train,y_test))\n",
        "  scores_svm.append(get_score(SVC(),X_train,X_test,y_train,y_test))\n",
        "  scores_rf.append(get_score(RandomForestClassifier(n_estimators=40),X_train,X_test,y_train,y_test))\n",
        "  #when i print 1st iteration 3 model perform . same as 2nd and 3rd iteration."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krYBwj3sNhjv",
        "outputId": "fc3fae09-5956-407a-8515-7f3413ea2191"
      },
      "source": [
        "#Now my scores should be ready . Now i print them\n",
        "scores_lr"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9232053422370617, 0.9415692821368948, 0.9148580968280468]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp9ws7swVeax",
        "outputId": "0c396d5c-4c21-4c2e-8645-63d8afb064a3"
      },
      "source": [
        "scores_svm"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9666110183639399, 0.9816360601001669, 0.9549248747913188]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0VGUa_2Ve11",
        "outputId": "0399777b-8600-421a-c6c0-1534d4c37d40"
      },
      "source": [
        "scores_rf\n",
        "#What u can do this u can take the avg score of these 3 and u can determine the best best model for a given problem.\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9365609348914858, 0.9465776293823038, 0.9131886477462438]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1OiZ73XVpS9"
      },
      "source": [
        "#now this appended type code is little massy bcz we have deal with so many indexes .\n",
        "#But lucky sklearn lib comes up with a readymate method called CrossValScore which u can use the to do the exact same thing i did here . in append array lines.\n",
        "#So this thing i wrote this code just to explain u how kFolds works.But in real life we are solving ML problem. U don't write this much code . U just call CrossValScore Method.\n",
        "#Which i can demo it here right now.\n",
        "from sklearn.model_selection import cross_val_score "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrW5nILUWjaB",
        "outputId": "4e099e64-9608-4cc8-b4c6-3a336082cabf"
      },
      "source": [
        "# and once the method is imported u can call this method \n",
        "#1st argument is ur classifier , 2nd is ur x and 3rd is ur y\n",
        "cross_val_score(LogisticRegression(),digits.data,digits.target)\n",
        "#the answer is same as like the previously \n",
        "#So internally that method did the same thing as for loopof append basically \n",
        "#it created folds and measure the performance and it repare the codes array \n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92222222, 0.86944444, 0.94150418, 0.93871866, 0.89693593])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYKYgYvhYa-W",
        "outputId": "4a12c5b7-6af0-4d48-ca1f-5b7a995201bc"
      },
      "source": [
        "#i will now call the same method on my SVM classifier \n",
        "cross_val_score(SVC(),digits.data,digits.target)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9joaXcT_aELd",
        "outputId": "d621b3e6-977e-410e-d0bb-f09c3da8ce8d"
      },
      "source": [
        "#in my 3rd case\n",
        "cross_val_score(RandomForestClassifier(n_estimators=40),digits.data,digits.target)\n",
        "#it just do that in 1 line man . ML is not hard . If u know the inernal of these libraries then all u need to do is just call 1 single method .\n",
        "#and its measuring the performance .\n",
        "#we compared different classifiers. u can compare same classifier with different parameters. This is called parameter tunning.\n",
        "#For ef we have RandomForestClassifier. we run with 40 trees . \n",
        " "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.93888889, 0.91111111, 0.95543175, 0.96657382, 0.91086351])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo3tDO-aaEg6",
        "outputId": "f3703f83-5762-4723-8c64-dbd2ed3b41e9"
      },
      "source": [
        "#We actually run the same classifier with let say 5 trees the score will down the little bit.\n",
        "cross_val_score(RandomForestClassifier(n_estimators=5),digits.data,digits.target)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87222222, 0.75277778, 0.89972145, 0.92479109, 0.86350975])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOgez_ZscIKe",
        "outputId": "9538cba2-fd0c-4e63-92cb-e486e06350d8"
      },
      "source": [
        "#let we try 15 for eg\n",
        "cross_val_score(RandomForestClassifier(n_estimators=15),digits.data,digits.target)\n",
        "#and the score will little bit up"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91666667, 0.90555556, 0.93036212, 0.94707521, 0.89415042])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krCmEBpicaE2",
        "outputId": "73c28e1b-e131-40ca-e96d-60bf624d9f4f"
      },
      "source": [
        "#So look like as increase my trees my score is increasing\n",
        "cross_val_score(RandomForestClassifier(n_estimators=50),digits.data,digits.target)\n",
        "#So in this way u can take a model and do parameter tuning . \n",
        "#So use the same algorithm basically here RandomForestClassifier\n",
        "#But tunning the parameters and trying to guage which 1 deliver the best 1 performance \n",
        "#So u can see that cross validation technique is prety useful.\n",
        "#It not only allows u to compare different algorithms. But same algorithms with different parameters . How it would be have for ur given problem.\n",
        "#It can tell u that.\n",
        "#So ML is not a scientific eq where for given problem u use this model verses that model something a little bit like trial and error based .\n",
        "#For ur given prolem and given data set u need to try a vrious model with various parameters and then figure out which one is best for one use case \n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91666667, 0.89444444, 0.96657382, 0.96100279, 0.91643454])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc1zD6k2czXp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}